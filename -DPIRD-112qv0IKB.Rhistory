"Size_DblN_ascend_se_Southern.shark_1(3)_BLK1mult_1994","Size_DblN_ascend_se_Southern.shark_1(3)_BLK1mult_2000",
"Size_DblN_descend_se_Southern.shark_1(3)_BLK1mult_1994","Size_DblN_descend_se_Southern.shark_1(3)_BLK1mult_2000")
BLK.pat$'Whiskery shark'=c("LnQ_base_Southern.shark_1(3)_BLK1repl_1975","LnQ_base_Southern.shark_1(3)_BLK1repl_1984")
tic()
for(i in 1:N.sp)
{
#set up paths
sp_path_assessment=paste(in.path,paste0('1.',Keep.species[i]),assessment.year,'SS3 integrated',sep='/')
sp_path_OM=paste(out.path.SSMSE,Keep.species[i],'OM',sep='/')
sp_path_EM=paste(out.path.SSMSE,Keep.species[i],'EM',sep='/')
sp_path_out=paste(out.path.SSMSE,Keep.species[i],'Outputs',sep='/')
fn.create.folder(x=sp_path_OM)
fn.create.folder(x=sp_path_EM)
fn.create.folder(x=sp_path_out)
Scenarios=SCENARIOS[[i]]
for(s in 1:nrow(Scenarios))
{
print(paste('SSMSE create files for ',Keep.species[i],'    Scenario',Scenarios$Scenario[s],'-----------'))
Indoktch=NULL
if(!is.na(Scenarios$Difference[s]) & Scenarios$Difference[s]=="IUU")
{
Indoktch=Catch.species.dataset%>%filter(Name==Keep.species[i] & Data.set=="Indonesia")
}
fn.create.SSMSE.files(sp_path_assessment, sp_path_OM, sp_path_EM, Scen=Scenarios[s,],
proj.yrs=Proj.years, proj.yrs.with.obs=Proj.years.obs,
Neff.future=NULL,block.pattern=BLK.pat[[i]])
} #end s
rm(sp_path_assessment,sp_path_OM,sp_path_EM,Scenarios)
} #end i
toc()
}
i
s
Scen=Scenarios[s,]
proj.yrs=Proj.years; proj.yrs.with.obs=Proj.years.obs;
Neff.future=NULL;block.pattern=BLK.pat[[i]]
#1. Bring in Assessment model
Assessment.location=paste(sp_path_assessment,Scen$Assessment.path,sep='/')
list.of.files <-list.files(Assessment.location) %>%
stringr::str_subset(., paste(c("plots","Diagnostics","sigma 0.4","ss.b0","ss.p0","ss.r0","admodel",
"console.output.txt","ss.cor","ss.eva","suggested_tuning.ss","ss.std",
"A no var adj","estim male offset","MonteCarlo",".tiff",".csv"),
collapse = '|'), negate = TRUE)
Assessment.location
#2. Create OM and EM based on Assessment model
scen_path_OM=paste(sp_path_OM,Scen$Scenario,sep='/')
fn.create.folder(scen_path_OM)
scen_path_EM=paste(sp_path_EM,Scen$Scenario,sep='/')
fn.create.folder(scen_path_EM)
invisible(lapply(list.of.files, function(x) file.copy(paste(Assessment.location, x, sep = "/"), to = scen_path_OM, recursive = TRUE)))
invisible(lapply(list.of.files, function(x) file.copy(paste(Assessment.location, x, sep = "/"), to = scen_path_EM, recursive = TRUE)))
Report=SS_output(scen_path_EM,covar=F,forecast=F,readwt=F,verbose = F, printstats=F)
fore.OM <- r4ss::SS_readforecast(file.path(scen_path_OM, "forecast.ss"),verbose = FALSE)
dat <- r4ss::SS_readdat(file.path(scen_path_OM, "data.dat"),verbose = FALSE)
dat.new <- r4ss::SS_readdat(file.path(scen_path_OM, "data_echo.ss_new"),verbose = FALSE)
control <- r4ss::SS_readctl(file.path(scen_path_OM, "control.ctl"),verbose = FALSE)
control.new <- r4ss::SS_readctl(file.path(scen_path_OM, "control.ss_new"),verbose = FALSE)
dat.EM <- r4ss::SS_readdat(file.path(scen_path_EM, "data.dat"),verbose = FALSE)
control.EM <- r4ss::SS_readctl(file.path(scen_path_EM, "control.ctl"),verbose = FALSE)
par.file <- SS_readRatPack.object(file.path(scen_path_OM,'ss.par'))
Scen
if(!is.na(Scen$Difference))
{
if(Scen$Difference=='NSF.logis.sel')
{
control$size_selex_types[match('Northern.shark',row.names(control$size_selex_types)),'Pattern']=1
id=match(c("SizeSel_P_3_Northern.shark(1)","SizeSel_P_4_Northern.shark(1)",
"SizeSel_P_5_Northern.shark(1)","SizeSel_P_6_Northern.shark(1)"),
row.names(control$size_selex_parms))
control$size_selex_parms=control$size_selex_parms[-id,]
id=match('SizeSel_P_1_Northern.shark(1)',row.names(control$size_selex_parms))
aaa=control$MG_parms[match('Mat50%_Fem_GP_1',row.names(control$MG_parms)),'INIT']
control$size_selex_parms[id,c('LO','HI','INIT','PRIOR')]=c(aaa*.8,aaa*1.2,aaa,aaa)
id=match('SizeSel_P_2_Northern.shark(1)',row.names(control$size_selex_parms))
control$size_selex_parms[id,c('LO','HI','INIT','PRIOR')]=c(1,20,10,10)
}
if(Scen$Difference=='lower.steepness')
{
control$SR_parms[match('SR_BH_steep',row.names(control$SR_parms)),c('LO','INIT')]=c(0.25,Scen$Difference.value)
}
if(Scen$Difference=='M.contstant')
{
nn=ncol(control$natM)
control$natM[1,]=rep(Scen$Difference.value,nn)
control$natM[2,]=rep(Scen$Difference.value,nn)
}
if(Scen$Difference=='rep.cycle')
{
control$MG_parms[match('Eggs_alpha_Fem_GP_1',row.names(control$MG_parms)),'INIT']=
control$MG_parms[match('Eggs_alpha_Fem_GP_1',row.names(control$MG_parms)),'INIT']*Scen$Difference.value
control$MG_parms[match('Eggs_beta_Fem_GP_1',row.names(control$MG_parms)),'INIT']=
control$MG_parms[match('Eggs_beta_Fem_GP_1',row.names(control$MG_parms)),'INIT']*Scen$Difference.value
}
if(Scen$Difference=='IUU')
{
id=match('Other',dat$fleetinfo$fleetname)
a=dat$catch%>%filter(fleet==id)
dat$catch=dat$catch%>%filter(!fleet==id)
a=left_join(a,Indoktch%>%
dplyr::select(Year,catch)%>%rename(catch1=catch),
by=c('year'='Year'))%>%
mutate(catch1=ifelse(is.na(catch1),0,catch1),
catch=catch-catch1,
catch=catch+(catch1*Scen$Difference.value))%>%
dplyr::select(-catch1)
dat$catch=rbind(a,dat$catch)%>%arrange(fleet,year,seas)
}
}
#Nathan Vaughan suggestions
par.file[[match("# Fcast_recruitments:",par.file)+1]]=" 0.00000000000 0.00000000000"
control$recdev_early_start=control.new$recdev_early_start=control.EM$recdev_early_start=1922
control$recdev_early_phase=control.new$recdev_early_phase=control.EM$recdev_early_phase=3
control$Fcast_recr_phase=control.new$Fcast_recr_phase=control.EM$Fcast_recr_phase=-2
control$time_vary_auto_generation[control$time_vary_auto_generation<1]=1
control.new$time_vary_auto_generation[control.new$time_vary_auto_generation<1]=1
control.EM$time_vary_auto_generation[control.EM$time_vary_auto_generation<1]=1
if('CPUE'%in%names(dat)) dat$CPUE$seas=dat.new$CPUE$seas=dat.EM$CPUE$seas=7
block.pattern
!is.null(block.pattern)
iid=match(block.pattern,rownames(Report$estimated_non_dev_parameters))
iid
any(grepl('LnQ',block.pattern))
any(grepl('Size_',block.pattern))
control.EM$size_selex_parms[,c('LO','HI','INIT','PRIOR','PR_SD','PR_type','PHASE')]
Report$estimated_non_dev_parameters[iid,'Value']
dum=control.EM$size_selex_parms[,c('LO','HI','INIT','PRIOR','PR_SD','PR_type','PHASE')]
dum=dum[iid,]
dum
dum%>%
mutate(INIT2=Report$estimated_non_dev_parameters[iid,'Value'])
block.pattern
# Header ---------------
# This script uses SSMSE and RatPack to perform Management Strategy Procedures to inform the development of the
#   Shark resource Harvest Strategy based on the 4 indicator species
#notes: Alternative state of nature are considered thru multiple OM (Operating Model):
#             Alternative hypothesis on Steepness, Natural mortality, selectivity and illegal fishing
#       Alternative harvest control rules and reference points are considered thru multiple EM (Estimation Model):
#             Alternative values of limit, threshold and target reference points
#       The Alternative OM and EM are defined in hndl.mse.comp below based a the 'Scenarios' spreadsheet
#       Most files are set up automatically by this script but there is some manual tweaking to be done:
#           RatPack: manually update the .OPD, .HSE and .proj files in the 'inputs' folder using values
#                    from input_HSE.txt and input_OPD.txt
#           SSMSE: for time changing parameters (e.g., blocks) add 'control_timevary_' to the control file in the EM
# SSMSE reference material:
#     https://nmfs-fish-tools.github.io/SSMSE/manual
#     https://github.com/nmfs-fish-tools/SSMSE/blob/main/README.md
#     https://github.com/k-doering-NOAA/ssmse-wfc
#     https://noaa-fisheries-integrated-toolbox.github.io/SSMSE
#HCL
#DPIRD's:
# 50-100% effort reduction if performance indicator between limit and threshold
# 10-50% effort reduction if performance indicator between threshold and target
#MSC guidelines:
# Bring back to threshold within 1 generation if between limit and threshold and
# within another generation if between threshold and target
#remotes::install_github("nmfs-fish-tools/SSMSE")
library(SSMSE)
library(r4ss)
library(tictoc)
library(tidyverse)
library(readxl)
library(doParallel)
#library(Hmisc)
# Set up paths and source functions  ---------------
fn.user=function(x1,x2)paste(x1,Sys.getenv("USERNAME"),x2,sep='/')
if(!exists('handl_OneDrive')) source(fn.user(x1='C:/Users',
x2='OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/SOURCE_SCRIPTS/Git_other/handl_OneDrive.R'))
source.hnld=handl_OneDrive("Analyses/MSE/Git_MSE/")
fn.source=function(script)source(paste(source.hnld,script,sep=""))
fn.source("2024_Shark_auxiliary functions.R")
#year latest stock assessment
assessment.year=2022
#SS files used in stock assessments
in.path=handl_OneDrive("Analyses/Population dynamics")  #path to SS3 stock assessments files
#paths for each method
out.path.SSMSE=handl_OneDrive("Analyses/MSE/Shark harvest strategy/SSMSE")
out.path.RatPack=handl_OneDrive("Analyses/MSE/Shark harvest strategy/RatPack")
#overall outputs
outs=handl_OneDrive("Analyses/MSE/Shark harvest strategy/z_Outputs")
# Define MSE components ---------------
#Components:
# 1. Management objectives
# 2. Operating Models
# 3. Estimation models (management scenarios)
# 4. Harvest control rules
# 5. Performance measures
# 6. Future data collection
#Scenarios
hndl.mse.comp=handl_OneDrive("Analyses/MSE/Shark harvest strategy/Scenarios.xlsx")
Management_objectives=read_excel(hndl.mse.comp,  sheet = "Management objectives",skip = 0)
Operating_models=read_excel(hndl.mse.comp,       sheet = "Operating model",skip = 0)
Management_scenarios=read_excel(hndl.mse.comp,   sheet = "Estimation model",skip = 0)
harvest_control_rule=read_excel(hndl.mse.comp, sheet = "harvest control rule",skip = 0)
performance_indicators=read_excel(hndl.mse.comp, sheet = "Performance measure",skip = 0)
Future_data_collection=read_excel(hndl.mse.comp, sheet = "Future data collection",skip = 0)
#Historic catch ranges
Target.commercial.catch=Management_objectives%>%
filter(Ojective.status=='Current')%>%
mutate(Type=ifelse(grepl('minimum',Objective),'Min.tones',
ifelse(grepl('maximum',Objective),'Max.tones',
NA)))%>%
filter(!is.na(Type))%>%
dplyr::select(Species,Type,Value)%>%
spread(Type,Value)%>%
relocate(Species,Min.tones,Max.tones)
Catch.species.dataset=read.csv(handl_OneDrive("Analyses/Population dynamics/PSA/Annual_ktch_by_species.and.data.set.csv"))
# Define global parameters ---------------
First.Run.SSMSE=FALSE                  # set to TRUE to generate OMs, Folders, etc
First.Run.RatPack=FALSE
niters <- 2                            # number of simulations per scenario (100)
Proj.years=10                          # number of projected years (25)
Proj.years.obs=seq(1,Proj.years,by=5)  # sampled years in the projected period
Proj.years.between.ass=2               # years between assessments in the projected period
proj.CV=0.2                            # CV in the projected period
Effective.pop.size.future=100          #future length comp sample size
theme_set(theme_light() +
theme(panel.grid.major.x = element_blank(),
panel.grid.minor = element_blank(),
panel.grid.major.y = element_blank(),
strip.background = element_rect(fill="white"),
strip.text = element_text(colour = 'black'),
text = element_text(family = "Calibri", size = 12)))
Keep.species=sort(unique(Operating_models$Species))
N.sp=length(Keep.species)
species_logistic.selectivity.NSF=sort(unique(Operating_models%>%filter(!is.na(NSF.selectivity))%>%pull(Species)))
species_IUU_indonesia=sort(unique(Operating_models%>%filter(!is.na(Indo.IUU))%>%pull(Species)))
subset.scenarios=TRUE  #test scenario grid?? way time consuming
# Create relevant directories and handles for each MSE framework  ---------------
#SSMSE
for(s in 1:N.sp) fn.create.folder(x=paste(out.path.SSMSE,Keep.species[s],sep='/'))
#RatPack
for(s in 1:N.sp) fn.create.folder(x=paste(out.path.RatPack,Keep.species[s],sep='/'))
hndl.RatPack=handl_OneDrive('Analyses/MSE/RatPack') #path to original files
# Create MSE scenarios ---------------
SCENARIOS=fn.create.list(Keep.species)
for(i in 1:N.sp)
{
#Alternative OMs
#note: these are the SS models used in the stock assessment sensitivity tests
OM_scenarios=Operating_models%>%
filter(Species==Keep.species[i])%>%
mutate(Assessment.path=case_when(!Scenario.source=='New'~ sub('.*_', '', Scenario.source),
Scenario.source=='New'~'S1'))%>%
dplyr::select(Assessment.path,Difference,Difference.value)%>%
data.frame%>%mutate(row.number=row_number())
#Define MSE scenarios (combination of OMs and Harvest strategies)
dd=merge(Management_scenarios,OM_scenarios,by=NULL)%>%
arrange(row.number,Ref.point)%>%
mutate(Scenario=paste0('S',row_number()))%>%
relocate(Ref.point,Scenario)%>%dplyr::select(-row.number)
if(subset.scenarios)
{
dd=dd%>%
mutate(Keep=ifelse(Ref.point=='0.5_1_1.2' | is.na(Difference),'YES','NO'))%>%
filter(Keep=='YES')%>%dplyr::select(-Keep)
}
SCENARIOS[[i]]=dd%>%mutate(Scenario=paste0('S',row_number()))%>%mutate(Species=Keep.species[i])
}
# Run SSMSE loop over each species-scenario combination ---------------
#1. Create SSMSE folders and files
if(First.Run.SSMSE)
{
#specify time changing parameters
BLK.pat=fn.create.list(Keep.species)
BLK.pat$'Sandbar shark'=c("Size_DblN_peak_Southern.shark_1(3)_BLK1mult_1994","Size_DblN_peak_Southern.shark_1(3)_BLK1mult_2000",
"Size_DblN_ascend_se_Southern.shark_1(3)_BLK1mult_1994","Size_DblN_ascend_se_Southern.shark_1(3)_BLK1mult_2000",
"Size_DblN_descend_se_Southern.shark_1(3)_BLK1mult_1994","Size_DblN_descend_se_Southern.shark_1(3)_BLK1mult_2000")
BLK.pat$'Whiskery shark'=c("LnQ_base_Southern.shark_1(3)_BLK1repl_1975","LnQ_base_Southern.shark_1(3)_BLK1repl_1984")
tic()
for(i in 1:N.sp)
{
#set up paths
sp_path_assessment=paste(in.path,paste0('1.',Keep.species[i]),assessment.year,'SS3 integrated',sep='/')
sp_path_OM=paste(out.path.SSMSE,Keep.species[i],'OM',sep='/')
sp_path_EM=paste(out.path.SSMSE,Keep.species[i],'EM',sep='/')
sp_path_out=paste(out.path.SSMSE,Keep.species[i],'Outputs',sep='/')
fn.create.folder(x=sp_path_OM)
fn.create.folder(x=sp_path_EM)
fn.create.folder(x=sp_path_out)
Scenarios=SCENARIOS[[i]]
for(s in 1:nrow(Scenarios))
{
print(paste('SSMSE create files for ',Keep.species[i],'    Scenario',Scenarios$Scenario[s],'-----------'))
Indoktch=NULL
if(!is.na(Scenarios$Difference[s]) & Scenarios$Difference[s]=="IUU")
{
Indoktch=Catch.species.dataset%>%filter(Name==Keep.species[i] & Data.set=="Indonesia")
}
fn.create.SSMSE.files(sp_path_assessment, sp_path_OM, sp_path_EM, Scen=Scenarios[s,],
proj.yrs=Proj.years, block.pattern=BLK.pat[[i]])
} #end s
rm(sp_path_assessment,sp_path_OM,sp_path_EM,Scenarios)
} #end i
toc()
}
i=4
s=1
Scenarios=SCENARIOS[[i]]
sp_path_assessment=paste(in.path,paste0('1.',Keep.species[i]),assessment.year,'SS3 integrated',sep='/')
sp_path_OM=paste(out.path.SSMSE,Keep.species[i],'OM',sep='/')
sp_path_EM=paste(out.path.SSMSE,Keep.species[i],'EM',sep='/')
sp_path_out=paste(out.path.SSMSE,Keep.species[i],'Outputs',sep='/')
print(paste('SSMSE run for ',Keep.species[i],'    Scenario',Scenarios$Scenario[s],'-----------'))
Scen=Scenarios[s,]
Nsims=niters; Neff.future=Effective.pop.size.future;
proj.yrs=Proj.years; proj.yrs.with.obs=Proj.years.obs;
yrs.between.assess=Proj.years.between.ass;
cur.fleets=c('Other','Southern.shark_2'); future.cv=proj.CV
scen_path_OM=paste(sp_path_OM,Scen$Scenario,sep='/')
scen_path_EM=paste(sp_path_EM,Scen$Scenario,sep='/')
dat <- r4ss::SS_readdat(file.path(scen_path_OM, "data.dat"),verbose = FALSE)
control <- r4ss::SS_readctl(file.path(paste(sp_path_assessment,Scen$Assessment.path,sep='/'), "control.ctl"),verbose = FALSE)
current.fleets=grep(paste(cur.fleets,collapse='|'),dat$fleetinfo$fleetname)
datfile_path=file.path(scen_path_OM, "data.dat")
future.ktch.yrs=(dat$endyr+1):(dat$endyr+proj.yrs)
future.ktch.fleets=length(unique(dat$catch$fleet))
future.ktch=data.frame(Yr=rep(future.ktch.yrs,future.ktch.fleets),
Seas=1,
FltSvy=rep(1:future.ktch.fleets,each=proj.yrs),
SE=0.01) #   filter(FltSvy%in%current.fleets)   #doesn't work if excluding fleets
#CPUE
future.CPUE=NA
future.obs.yrs=sort(unique(future.ktch$Yr))
future.obs.yrs=future.obs.yrs[proj.yrs.with.obs]
if('index'%in%colnames(dat$CPUE))
{
future.CPUE <- expand.grid(Yr = future.obs.yrs,
Seas = unique(dat$CPUE$seas),
FltSvy = unique(dat$CPUE$index),
SE=future.cv)%>%filter(FltSvy%in%current.fleets)
}
#length comps
future.lengcomp=NA
future.Neff=round(mean(dat$lencomp$Nsamp))
if(nrow(dat$lencomp)>0)
{
future.lengcomp <- expand.grid(Yr = future.obs.yrs,
Seas = unique(dat$lencomp$Seas),
FltSvy = unique(dat$lencomp$FltSvy),
Sex = 1:2,
Part = unique(dat$lencomp$Part),
Nsamp = Neff.future)%>%
filter(FltSvy%in%current.fleets)
}
#mean body weight
future.meanbodywt=NA
# if(!is.null(dat$meanbodywt))
# {
#   future.meanbodywt <- expand.grid(Yr = future.obs.yrs,
#                                    Seas = unique(dat$meanbodywt$Seas),
#                                    FltSvy = unique(dat$meanbodywt$Fleet),
#                                    Part = unique(dat$meanbodywt$Part),
#                                    Type = unique(dat$meanbodywt$Type),
#                                    SE = future.cv)%>%filter(FltSvy%in%current.fleets)
# }  #doesn't work with meanbodywt
samp_struct_list=list(list(catch=future.ktch,
CPUE=future.CPUE,
lencomp=future.lengcomp,
agecomp=NA,
meanbodywt=future.meanbodywt,
MeanSize_at_Age_obs=NA))
names(samp_struct_list)=Scen$Scenario
#2. Create future OM
first.future.yr=dat$endyr+1
template_mod_change <- SSMSE::create_future_om_list(example_type = "model_change")
#Random fluctuations in rec devs
rec_dev_specify <- template_mod_change[[1]]
rec_dev_specify$pars <- "rec_devs"
rec_dev_specify$scen <- c("replicate", "all") # use c("random", "all") if did not want to replicate the same recdevs across scenarios
rec_dev_specify$input$first_yr_averaging <- dat$styr # use same sd as from the orig model.
rec_dev_specify$input$last_yr_averaging <- dat$endyr  #missing: update accordingly with my years
rec_dev_specify$input$last_yr_orig_val <- dat$endyr
rec_dev_specify$input$first_yr_final_val <- first.future.yr
rec_dev_specify$input$ts_param <- "sd"
rec_dev_specify$input$value <- NA
#Random fluctuations in gear selectivity
sel.pars=rownames(control$size_selex_parms)
mod_change_sel <- template_mod_change[[1]]
mod_change_sel$pars <- sel.pars[grep('SizeSel_P_1_Southern.shark_2',sel.pars)]
mod_change_sel$scen[2] <- "all"
mod_change_sel$input$last_yr_orig_val <- dat$endyr
mod_change_sel$input$first_yr_final_val <- first.future.yr
mod_change_sel$input$ts_param <- "sd"
mod_change_sel$input$value <- 0.2
future_om_list <- list(mod_change_sel, rec_dev_specify)
tic()
out <- SSMSE::run_SSMSE(scen_name_vec = Scen$Scenario,      # name of the scenario
out_dir_scen_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/Outputs",     # directory in which to run the scenario
iter_vec = Nsims,
OM_name_vec = NULL,                 # specify directory instead
OM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/OM",       # OM directory
EM_name_vec = NULL,                 # specify directory instead
EM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/EM",       # EM directory
run_EM_last_yr = FALSE,
MS_vec = "EM",                      # The management strategy is specified in the EM
use_SS_boot_vec = TRUE,
nyrs_vec = proj.yrs,                # Years to project OM forward
nyrs_assess_vec = yrs.between.assess,
sample_struct_list = samp_struct_list,
future_om_list = future_om_list,
verbose = TRUE,
seed = 666, # changing each time a chunk of runs is done will help ensure there is stochacisity
run_parallel = FALSE,
n_cores = parallelly::availableCores()-1)
tic()
out <- SSMSE::run_SSMSE(scen_name_vec = Scen$Scenario,      # name of the scenario
out_dir_scen_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/Outputs",     # directory in which to run the scenario
iter_vec = Nsims,
OM_name_vec = NULL,                 # specify directory instead
OM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/OM",       # OM directory
EM_name_vec = NULL,                 # specify directory instead
EM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/EM",       # EM directory
run_EM_last_yr = FALSE,
MS_vec = "EM",                      # The management strategy is specified in the EM
use_SS_boot_vec = TRUE,
nyrs_vec = proj.yrs,                # Years to project OM forward
nyrs_assess_vec = yrs.between.assess,
sample_struct_list = samp_struct_list,
future_om_list = future_om_list,
verbose = TRUE,
seed = 666, # changing each time a chunk of runs is done will help ensure there is stochacisity
run_parallel = FALSE,
n_cores = parallelly::availableCores()-1)
library(assertive.properties)
.libPaths()
?.libPaths
.libPaths("C:/Users/myb/AppData/Local/R/win-library/4.4")
.libPaths()
#library(Hmisc)
.libPaths("C:/Users/myb/AppData/Local/R/win-library/4.4")
tic()
out <- SSMSE::run_SSMSE(scen_name_vec = Scen$Scenario,      # name of the scenario
out_dir_scen_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/Outputs",     # directory in which to run the scenario
iter_vec = Nsims,
OM_name_vec = NULL,                 # specify directory instead
OM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/OM",       # OM directory
EM_name_vec = NULL,                 # specify directory instead
EM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/EM",       # EM directory
run_EM_last_yr = FALSE,
MS_vec = "EM",                      # The management strategy is specified in the EM
use_SS_boot_vec = TRUE,
nyrs_vec = proj.yrs,                # Years to project OM forward
nyrs_assess_vec = yrs.between.assess,
sample_struct_list = samp_struct_list,
future_om_list = future_om_list,
verbose = TRUE,
seed = 666, # changing each time a chunk of runs is done will help ensure there is stochacisity
run_parallel = FALSE,
n_cores = parallelly::availableCores()-1)
toc()
tic()
out <- SSMSE::run_SSMSE(scen_name_vec = Scen$Scenario,      # name of the scenario
out_dir_scen_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/Outputs",     # directory in which to run the scenario
iter_vec = Nsims,
OM_name_vec = NULL,                 # specify directory instead
OM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/OM",       # OM directory
EM_name_vec = NULL,                 # specify directory instead
EM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/EM",       # EM directory
run_EM_last_yr = FALSE,
MS_vec = "EM",                      # The management strategy is specified in the EM
use_SS_boot_vec = TRUE,
nyrs_vec = proj.yrs,                # Years to project OM forward
nyrs_assess_vec = yrs.between.assess,
sample_struct_list = samp_struct_list,
#future_om_list = future_om_list,
verbose = TRUE,
seed = 666, # changing each time a chunk of runs is done will help ensure there is stochacisity
run_parallel = FALSE,
n_cores = parallelly::availableCores()-1)
?run_SSMSE
specify.future.OM=FALSE
future_om_list <- list(mod_change_sel, rec_dev_specify)
future_OM=NULL
if(specify.future.OM)future_OM=future_om_list
future_OM
out <- SSMSE::run_SSMSE(scen_name_vec = Scen$Scenario,      # name of the scenario
out_dir_scen_vec = sp_path_out,     # directory in which to run the scenario
iter_vec = Nsims,
OM_name_vec = NULL,                 # specify directory instead
OM_in_dir_vec = scen_path_OM,       # OM directory
EM_name_vec = NULL,                 # specify directory instead
EM_in_dir_vec = scen_path_EM,       # EM directory
run_EM_last_yr = FALSE,
MS_vec = "EM",                      # The management strategy is specified in the EM
use_SS_boot_vec = TRUE,
nyrs_vec = proj.yrs,                # Years to project OM forward
nyrs_assess_vec = yrs.between.assess,
sample_struct_list = samp_struct_list,
future_om_list = future_OM,
verbose = TRUE,
seed = 666, # changing each time a chunk of runs is done will help ensure there is stochacisity
run_parallel = TRUE,
n_cores = parallelly::availableCores()-1)
tic()
out <- SSMSE::run_SSMSE(scen_name_vec = Scen$Scenario,      # name of the scenario
out_dir_scen_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/Outputs",     # directory in which to run the scenario
iter_vec = Nsims,
OM_name_vec = NULL,                 # specify directory instead
OM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/OM",       # OM directory
EM_name_vec = NULL,                 # specify directory instead
EM_in_dir_vec = "C:/Users/myb/OneDrive - Department of Primary Industries and Regional Development/Matias/Analyses/MSE/Z_Nathan Vaughan/1.Sent to nathan.vaughan/EM",       # EM directory
run_EM_last_yr = FALSE,
MS_vec = "EM",                      # The management strategy is specified in the EM
use_SS_boot_vec = TRUE,
nyrs_vec = proj.yrs,                # Years to project OM forward
nyrs_assess_vec = yrs.between.assess,
sample_struct_list = samp_struct_list,
future_om_list = future_OM,
verbose = TRUE,
seed = 666, # changing each time a chunk of runs is done will help ensure there is stochacisity
run_parallel = FALSE,
n_cores = parallelly::availableCores()-1)
